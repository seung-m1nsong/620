{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObriK_kQ7fFC"
      },
      "source": [
        "# **Project 2**\n",
        "Seung Min Song, Krutika Patel<br>\n",
        "\n",
        "03/05/2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Source**\n",
        "\n",
        "* https://www.kaggle.com/datasets/andrewmvd/data-scientist-jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "ename": "IncompleteRead",
          "evalue": "IncompleteRead(14693376 bytes read, 264240 more expected)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://raw.githubusercontent.com/seung-m1nsong/620/main/Project2/DataScientist.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m ds\u001b[38;5;241m.\u001b[39mhead()\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 713\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    722\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:368\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    366\u001b[0m             \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[0;32m    367\u001b[0m             compression \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 368\u001b[0m         reader \u001b[38;5;241m=\u001b[39m BytesIO(\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    370\u001b[0m         filepath_or_buffer\u001b[38;5;241m=\u001b[39mreader,\n\u001b[0;32m    371\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfsspec_mode,\n\u001b[0;32m    375\u001b[0m     )\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:481\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32mc:\\Users\\SeungminSong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:632\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(14693376 bytes read, 264240 more expected)"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "ds = pd.read_csv('https://raw.githubusercontent.com/seung-m1nsong/620/main/Project2/DataScientist.csv')\n",
        "\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Wrangling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = ds.drop(ds.columns[0], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Salary Estimate</th>\n",
              "      <th>Job Description</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Company Name</th>\n",
              "      <th>Location</th>\n",
              "      <th>Headquarters</th>\n",
              "      <th>Size</th>\n",
              "      <th>Founded</th>\n",
              "      <th>Type of ownership</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Revenue</th>\n",
              "      <th>Competitors</th>\n",
              "      <th>Easy Apply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Senior Data Scientist</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>Hopper\\n3.5</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Montreal, Canada</td>\n",
              "      <td>501 to 1000 employees</td>\n",
              "      <td>2007</td>\n",
              "      <td>Company - Private</td>\n",
              "      <td>Travel Agencies</td>\n",
              "      <td>Travel &amp; Tourism</td>\n",
              "      <td>Unknown / Non-Applicable</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Data Scientist, Product Analytics</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>At Noom, we use scientifically proven methods ...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>Noom US\\n4.5</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>1001 to 5000 employees</td>\n",
              "      <td>2008</td>\n",
              "      <td>Company - Private</td>\n",
              "      <td>Health, Beauty, &amp; Fitness</td>\n",
              "      <td>Consumer Services</td>\n",
              "      <td>Unknown / Non-Applicable</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Data Science Manager</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>Decode_M</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>1 to 50 employees</td>\n",
              "      <td>-1</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>Unknown / Non-Applicable</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>Sapphire Digital seeks a dynamic and driven mi...</td>\n",
              "      <td>3.4</td>\n",
              "      <td>Sapphire Digital\\n3.4</td>\n",
              "      <td>Lyndhurst, NJ</td>\n",
              "      <td>Lyndhurst, NJ</td>\n",
              "      <td>201 to 500 employees</td>\n",
              "      <td>2019</td>\n",
              "      <td>Company - Private</td>\n",
              "      <td>Internet</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Unknown / Non-Applicable</td>\n",
              "      <td>Zocdoc, Healthgrades</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Director, Data Science</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>Director, Data Science - (200537)\\nDescription...</td>\n",
              "      <td>3.4</td>\n",
              "      <td>United Entertainment Group\\n3.4</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>51 to 200 employees</td>\n",
              "      <td>2007</td>\n",
              "      <td>Company - Private</td>\n",
              "      <td>Advertising &amp; Marketing</td>\n",
              "      <td>Business Services</td>\n",
              "      <td>Unknown / Non-Applicable</td>\n",
              "      <td>BBDO, Grey Group, Droga5</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                          Job Title Salary Estimate  \\\n",
              "0      0              Senior Data Scientist     $111K-$181K   \n",
              "1      1  Data Scientist, Product Analytics     $111K-$181K   \n",
              "2      2               Data Science Manager     $111K-$181K   \n",
              "3      3                       Data Analyst     $111K-$181K   \n",
              "4      4             Director, Data Science     $111K-$181K   \n",
              "\n",
              "                                     Job Description  Rating  \\\n",
              "0  ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...     3.5   \n",
              "1  At Noom, we use scientifically proven methods ...     4.5   \n",
              "2  Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...    -1.0   \n",
              "3  Sapphire Digital seeks a dynamic and driven mi...     3.4   \n",
              "4  Director, Data Science - (200537)\\nDescription...     3.4   \n",
              "\n",
              "                      Company Name       Location      Headquarters  \\\n",
              "0                      Hopper\\n3.5   New York, NY  Montreal, Canada   \n",
              "1                     Noom US\\n4.5   New York, NY      New York, NY   \n",
              "2                         Decode_M   New York, NY      New York, NY   \n",
              "3            Sapphire Digital\\n3.4  Lyndhurst, NJ     Lyndhurst, NJ   \n",
              "4  United Entertainment Group\\n3.4   New York, NY      New York, NY   \n",
              "\n",
              "                     Size  Founded  Type of ownership  \\\n",
              "0   501 to 1000 employees     2007  Company - Private   \n",
              "1  1001 to 5000 employees     2008  Company - Private   \n",
              "2       1 to 50 employees       -1            Unknown   \n",
              "3    201 to 500 employees     2019  Company - Private   \n",
              "4     51 to 200 employees     2007  Company - Private   \n",
              "\n",
              "                    Industry                  Sector  \\\n",
              "0            Travel Agencies        Travel & Tourism   \n",
              "1  Health, Beauty, & Fitness       Consumer Services   \n",
              "2                         -1                      -1   \n",
              "3                   Internet  Information Technology   \n",
              "4    Advertising & Marketing       Business Services   \n",
              "\n",
              "                    Revenue               Competitors Easy Apply  \n",
              "0  Unknown / Non-Applicable                        -1         -1  \n",
              "1  Unknown / Non-Applicable                        -1         -1  \n",
              "2  Unknown / Non-Applicable                        -1       True  \n",
              "3  Unknown / Non-Applicable      Zocdoc, Healthgrades         -1  \n",
              "4  Unknown / Non-Applicable  BBDO, Grey Group, Droga5         -1  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['Salary Estimate'] = ds['Salary Estimate'].apply(lambda x: x.replace(' (Glassdoor est.)', ''))\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Salary Estimate</th>\n",
              "      <th>Location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Senior Data Scientist</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>New York, NY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist, Product Analytics</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>New York, NY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Science Manager</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>New York, NY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>Lyndhurst, NJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Director, Data Science</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>New York, NY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Job Title Salary Estimate       Location\n",
              "0              Senior Data Scientist     $111K-$181K   New York, NY\n",
              "1  Data Scientist, Product Analytics     $111K-$181K   New York, NY\n",
              "2               Data Science Manager     $111K-$181K   New York, NY\n",
              "3                       Data Analyst     $111K-$181K  Lyndhurst, NJ\n",
              "4             Director, Data Science     $111K-$181K   New York, NY"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_df = ds[['Job Title', 'Salary Estimate', 'Location']].copy()\n",
        "ds_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get information about the filtered DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3909 entries, 0 to 3908\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Job Title        3909 non-null   object\n",
            " 1   Salary Estimate  3909 non-null   object\n",
            " 2   Location         3909 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 91.7+ KB\n"
          ]
        }
      ],
      "source": [
        "ds_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job Title & Salary Estimate:\n",
            "                           Job Title Salary Estimate       Location\n",
            "0              Senior Data Scientist     $111K-$181K   New York, NY\n",
            "1  Data Scientist, Product Analytics     $111K-$181K   New York, NY\n",
            "2               Data Science Manager     $111K-$181K   New York, NY\n",
            "3                       Data Analyst     $111K-$181K  Lyndhurst, NJ\n",
            "4             Director, Data Science     $111K-$181K   New York, NY\n"
          ]
        }
      ],
      "source": [
        "# Create a data frame containing only the 'Job Title' and 'Salary Estimate' columns\n",
        "ds_job_salary_df = ds_df[['Job Title', 'Salary Estimate','Location']].copy()\n",
        "\n",
        "# Create a data frame containing only the ‘Job Title’ and ‘Location’ columns.\n",
        "ds_job_location_df = ds_df[['Job Title', 'Location']].copy()\n",
        "\n",
        "# result\n",
        "print(\"Job Title & Salary Estimate:\")\n",
        "print(ds_job_salary_df.head())\n",
        "#print(\"\\nJob Title & Location:\")\n",
        "#print(ds_job_location_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                              Source       Target\n",
            "0              Senior Data Scientist  $111K-$181K\n",
            "1  Data Scientist, Product Analytics  $111K-$181K\n",
            "2               Data Science Manager  $111K-$181K\n",
            "3                       Data Analyst  $111K-$181K\n",
            "4             Director, Data Science  $111K-$181K\n"
          ]
        }
      ],
      "source": [
        "nt = pd.DataFrame({'Source': ds_job_salary_df['Job Title'], 'Target': ds_job_salary_df['Salary Estimate']})\n",
        "print(nt.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Target</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Senior Data Scientist</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist, Product Analytics</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Science Manager</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Director, Data Science</td>\n",
              "      <td>$111K-$181K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3904</th>\n",
              "      <td>AWS Data Engineer</td>\n",
              "      <td>$55K-$112K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3905</th>\n",
              "      <td>Data Analyst â Junior</td>\n",
              "      <td>$55K-$112K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3906</th>\n",
              "      <td>Security Analytics Data Engineer</td>\n",
              "      <td>$55K-$112K</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>Security Analytics Data Engineer</td>\n",
              "      <td>$55K-$112K</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>Patient Safety Physician or Safety Scientist -...</td>\n",
              "      <td>$55K-$112K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3909 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Source       Target  weight\n",
              "0                                 Senior Data Scientist  $111K-$181K       1\n",
              "1                     Data Scientist, Product Analytics  $111K-$181K       1\n",
              "2                                  Data Science Manager  $111K-$181K       1\n",
              "3                                          Data Analyst  $111K-$181K       1\n",
              "4                                Director, Data Science  $111K-$181K       1\n",
              "...                                                 ...          ...     ...\n",
              "3904                                  AWS Data Engineer   $55K-$112K       1\n",
              "3905                              Data Analyst â Junior   $55K-$112K       1\n",
              "3906                   Security Analytics Data Engineer   $55K-$112K       2\n",
              "3907                   Security Analytics Data Engineer   $55K-$112K       2\n",
              "3908  Patient Safety Physician or Safety Scientist -...   $55K-$112K       1\n",
              "\n",
              "[3909 rows x 3 columns]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nt['weight'] = nt.groupby(['Source', 'Target'])['Source'].transform('size')\n",
        "nt = nt.dropna()\n",
        "\n",
        "G = nx.from_pandas_edgelist(nt, 'Source', 'Target',\n",
        "                            create_using=nx.DiGraph(), edge_attr='weight')\n",
        "nt\n",
        "\n",
        "#nt.to_csv('nt1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             Source  weight\n",
            "656                  Data Scientist    2886\n",
            "376                    Data Analyst    1064\n",
            "498                   Data Engineer    1052\n",
            "1707          Senior Data Scientist     267\n",
            "166               Big Data Engineer     109\n",
            "1148      Machine Learning Engineer      81\n",
            "1674            Senior Data Analyst      79\n",
            "1686           Senior Data Engineer      65\n",
            "227   Business Intelligence Analyst      57\n",
            "1559                      Scientist      35\n",
            "1485             Research Scientist      32\n",
            "1116            Lead Data Scientist      29\n",
            "1938             Sr. Data Scientist      29\n",
            "1657       Senior Big Data Engineer      27\n",
            "607                    Data Modeler      23\n"
          ]
        }
      ],
      "source": [
        "node_sizes = nt.groupby('Source').weight.agg(sum)\n",
        "n = node_sizes.add_suffix('').reset_index()\n",
        "top_15 =n.sort_values(by='weight', ascending=False).head(15)\n",
        "print(top_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 2227\n",
            "Number of edges: 3140\n",
            "Average degree: 2.819937135159407\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G = nx.from_pandas_edgelist(nt, 'Source', 'Target', ['weight'])\n",
        "print(\"Number of nodes:\", G.number_of_nodes())\n",
        "print(\"Number of edges:\", G.number_of_edges())\n",
        "print(\"Average degree:\", sum(dict(G.degree()).values()) / G.number_of_nodes())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the degree centrality of G: deg_cen\n",
        "deg_cen = nx.degree_centrality(G)\n",
        "sorted_deg_cen=sorted(deg_cen.items(), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "top_10_degree = sorted_deg_cen[:10]\n",
        "bottom_10_degree = sorted_deg_cen[-10:]\n",
        "\n",
        "print(\"Top 10 nodes by eigenvector centrality:\")\n",
        "for node, value in top_10_degree:\n",
        "    print(f\"{node}: {value}\")\n",
        "\n",
        "print(\"\\nBottom 10 nodes by eigenvector centrality:\")\n",
        "for node, value in bottom_10_degree:\n",
        "    print(f\"{node}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Degree Centrality: 0.0012668181200177035\n",
            "Max Degree Centrality: 0.04402515723270441\n",
            "Min Degree Centrality: 0.0004492362982929021\n",
            "Median Degree Centrality: 0.0004492362982929021\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Convert degree centrality values ​​to a list\n",
        "degree_centrality_values = [value for node, value in deg_cen.items()]\n",
        "\n",
        "# Calculate the average, maximum, minimum, and median of degree centrality values\n",
        "mean_degree_centrality = np.mean(degree_centrality_values)\n",
        "max_degree_centrality = np.max(degree_centrality_values)\n",
        "min_degree_centrality = np.min(degree_centrality_values)\n",
        "median_degree_centrality = np.median(degree_centrality_values)\n",
        "\n",
        "print(f\"Mean Degree Centrality: {mean_degree_centrality}\")\n",
        "print(f\"Max Degree Centrality: {max_degree_centrality}\")\n",
        "print(f\"Min Degree Centrality: {min_degree_centrality}\")\n",
        "print(f\"Median Degree Centrality: {median_degree_centrality}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 433\n",
            "Number of edges: 1347\n",
            "Average degree: 6.221709006928407\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G = nx.from_pandas_edgelist(nt, 'Source', 'Target', ['weight'])\n",
        "\n",
        "# Exclude nodes with degree centrality below the median\n",
        "nodes_to_remove = [n for n, centrality in deg_cen.items() if centrality <= median_degree_centrality]\n",
        "G.remove_nodes_from(nodes_to_remove)\n",
        "\n",
        "print(\"Number of nodes:\", G.number_of_nodes())\n",
        "print(\"Number of edges:\", G.number_of_edges())\n",
        "print(\"Average degree:\", sum(dict(G.degree()).values()) / G.number_of_nodes())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
          ]
        }
      ],
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "net = Network(notebook=True)\n",
        "\n",
        "for n in G.nodes():\n",
        "    if n in nt['Source'].tolist():\n",
        "        color = 'skyblue'\n",
        "    elif n in nt['Target'].tolist():\n",
        "        color = 'indianred'\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    # set size based on degree (number of edges)\n",
        "    size = 5 + 1.5 * G.degree(n)  # adjust the multiplier for desired size scaling\n",
        "    net.add_node(n, label=n, color=color, size=size)\n",
        "\n",
        "# add edges\n",
        "for edge in G.edges():\n",
        "    if edge[0] in net.get_nodes() and edge[1] in net.get_nodes():\n",
        "        net.add_edge(edge[0], edge[1], color='gray')  # Set edge color to black\n",
        "\n",
        "# show buttons for filtering nodes\n",
        "net.show_buttons(filter_=['nodes'])\n",
        "net.save_graph('JS_filtered.html')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
          ]
        }
      ],
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "net = Network(notebook=True)\n",
        "\n",
        "for n in G.nodes():\n",
        "    if n in nt['Source'].tolist():\n",
        "        color = 'skyblue'\n",
        "    elif n in nt['Target'].tolist():\n",
        "        color = 'indianred'\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    # set size based on degree (number of edges)\n",
        "    size = 5 + 1.5 * G.degree(n)  # adjust the multiplier for desired size scaling\n",
        "    net.add_node(n, label=n, color=color, size=size)\n",
        "\n",
        "# add edges\n",
        "for edge in G.edges():\n",
        "    if edge[0] in net.get_nodes() and edge[1] in net.get_nodes():\n",
        "        net.add_edge(edge[0], edge[1])\n",
        "\n",
        "\n",
        "# show buttons for filtering nodes\n",
        "net.show_buttons(filter_=['nodes'])\n",
        "net.save_graph('JS.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jeor-Mormont:  81\n",
            "Samwell-Tarly:  81\n",
            "Bran-Stark:  56\n",
            "Tyrion-Lannister:  56\n",
            "Robb-Stark:  53\n",
            "Pypar:  45\n",
            "Benjen-Stark:  41\n",
            "Eddard-Stark:  38\n",
            "Arya-Stark:  37\n",
            "Aemon-Targaryen-(Maester-Aemon):  34\n"
          ]
        }
      ],
      "source": [
        "# A function that outputs 10 neighbors in the order of highest weight between specific nodes (names) in network G\n",
        "\n",
        "def find_ten_closest(G, name):  \n",
        "    neighbors_list = list(G.neighbors(f\"{name}\"))\n",
        "    \n",
        "    temp_dict = {}\n",
        "    for n in neighbors_list:\n",
        "        if G.has_edge(f\"{name}\", n):\n",
        "            weight = G.edges[f\"{name}\", n]['weight']\n",
        "            temp_dict[n] = weight\n",
        "    \n",
        "    sorted_list = sorted(temp_dict.items(), key=(lambda x:x[1]), reverse=True)\n",
        "    for n, w in sorted_list[0:10]:  # 1~10위\n",
        "        print(f'{n}:  {w}')\n",
        "\n",
        "# Output the top 10 people closest to 'Jon-Snow' and their weight\n",
        "find_ten_closest(G, 'Jon-Snow')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
